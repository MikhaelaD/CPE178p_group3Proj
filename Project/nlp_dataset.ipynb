{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('path_to_your_file.csv')\n",
    "\n",
    "# Example CSV columns: 'text' and 'label'\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# Initialize the tokenizer for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Convert texts to tokenized format\n",
    "class TextDataset:\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded = self.tokenizer(text, return_tensors=\"ms\", padding=True, truncation=True)\n",
    "        input_ids = encoded[\"input_ids\"]\n",
    "        attention_mask = encoded[\"attention_mask\"]\n",
    "        return input_ids, attention_mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = GeneratorDataset(TextDataset(texts, labels, tokenizer), [\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
